# ğŸ§  Meeting Transcript Assistant

A FastAPI-based AI backend for managing meeting transcripts â€” enabling users to upload transcripts, query or summarize them with natural language, and retrieve intelligent responses using OpenAI, LangChain, Langfuse, and Astra DB.

---

## ğŸ“˜ Overview

This project is built to:
- ğŸ“ Store full meeting transcripts.
- ğŸ¤– Classify user queries as either summarization or question answering.
- ğŸ“¡ Retrieve relevant past meetings using metadata and vector similarity.
- ğŸ§  Use LLMs (GPT-4o) to answer or summarize with contextual precision.
- ğŸ” Observe and manage prompts using Langfuse.

---

## ğŸ§  How It Works

```mermaid
flowchart TD
    subgraph Client
        A[User<br/>Frontend / cURL / Postman]
    end

    subgraph FastAPI
        B(/POST /upload_transcript/)
        C(/POST /query/)
    end

    subgraph Chains
        D[MetadataÂ Extractor<br/>(LangChainÂ â†’ LLM)]
        E[IntentÂ Classifier<br/>(LangChainÂ â†’ LLM)]
        F[SummarizerÂ Chain<br/>(LLM w/ context)]
        G[QAÂ Chain<br/>(LLM w/ context)]
    end

    subgraph Storage
        H[[AstraÂ DB<br/>VectorÂ Store]]
    end

    subgraph Observability
        I[Langfuse<br/>Tracing / PromptÂ Mgmt]
    end

    A -->|transcript| B --> D
    D -->|topicÂ + date metadata| H
    B -->|trace| I

    A -->|query| C --> E
    E -->|intent| C
    C -->|extract topic/date| D
    C -->|vector search| H --> C

    C -->|route: summarization| F
    C -->|route: qa| G
    F -->|summary| A
    G -->|answer| A
    C -->|trace| I
```

---

## ğŸ“‚ Project Structure

```
ğŸ“ app/
â”œâ”€â”€ chains/
â”‚   â”œâ”€â”€ intent_classifier.py     # Detects intent + extracts topic/date
â”‚   â”œâ”€â”€ metadata_extractor.py    # Extracts metadata from transcripts
â”‚   â”œâ”€â”€ qa_chain.py              # Answers questions using relevant docs
â”‚   â””â”€â”€ summarizer_chain.py      # Summarizes documents based on query
â”œâ”€â”€ astra_store.py               # Astra DB vector storage logic
â”œâ”€â”€ langfuse.py                  # Langfuse prompt integration + tracing
â”œâ”€â”€ routes.py                    # FastAPI API routes
main.py                          # App entry point
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/meeting-transcript-assistant.git
cd meeting-transcript-assistant
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Add Environment Variables

Create a `.env` file in the root directory with:

```dotenv
OPENAI_API_KEY=your_openai_api_key

ASTRA_DB_ID=your_astra_db_id
ASTRA_DB_KEY=your_astra_db_key
ASTRA_DB_TABLE=meeting_transcripts
ASTRA_DB_API_ENDPOINT=https://your-db-id-region.apps.astra.datastax.com

LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_HOST=https://cloud.langfuse.com
```

### 4. Run the Application

```bash
uvicorn main:app --reload
```

> API docs will be available at [http://localhost:8000/docs](http://localhost:8000/docs)

### 4. Run the Prompts.py

```bash
cd prompts
python prompts.py
```

---

## ğŸ“¡ API Endpoints

### ğŸ”¹ POST `/upload_transcript`

**Request:**
```json
{
  "transcript": "Today we discussed updates for the Q3 marketing roadmap..."
}
```

**Response:**
```json
{
  "status": "stored",
  "metadata": {
    "topic": "q3 marketing",
    "date": "2025-07-13"
  }
}
```

---

### ğŸ”¹ POST `/query`

**Request:**
```json
{
  "query": "Can you summarize the meeting about Q3 marketing?"
}
```

**Response:**
```json
{
  "intent": "summarization",
  "result": "The meeting focused on Q3 product strategy, emphasizing customer outreach..."
}
```

---

## ğŸ§  Chain Breakdown

### âœ³ï¸ `intent_classifier.py`
- `detect_intent()`: Determines if the query is a question or summarization.
- `extract_topic_date()`: Extracts metadata fields from a natural language question.

### ğŸ·ï¸ `metadata_extractor.py`
- `extract_metadata()`: Extracts structured fields like topic/date from raw transcripts. Ensures JSON parsing and handles errors.

### â“ `qa_chain.py`
- `run_qa_chain()`: Answers user questions based on semantic search + context.

### ğŸ“ `summarizer_chain.py`
- `run_summarizer()`: Generates concise summaries for transcripts based on context and intent.

---

## ğŸ§ª Example Test with cURL

```bash
curl -X POST http://localhost:8000/upload_transcript -H "Content-Type: application/json" -d '{"transcript": "Yesterday we reviewed the AI project goals and challenges..."}'

curl -X POST http://localhost:8000/query -H "Content-Type: application/json" -d '{"query": "What were the goals mentioned in the AI meeting?"}'
```

---

## ğŸ“ˆ Observability with Langfuse

Langfuse is used to:
- Manage prompt templates (`detect_intent`, `extract_metadata`, `qa`, `summarizer`)
- Trace LLM calls and visualize latency, tokens, etc.
- Inject `CallbackHandler` for automatic logging.

---

## ğŸ§  Powered By

- [FastAPI](https://fastapi.tiangolo.com/)
- [LangChain](https://www.langchain.com/)
- [OpenAI GPT-4o](https://platform.openai.com/)
- [Astra DB](https://www.datastax.com/astra)
- [Langfuse](https://langfuse.com/)

---

## ğŸ“„ License

This project is licensed under the MIT License.